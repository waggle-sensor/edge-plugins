#!/usr/bin/env python3
# ANL:waggle-license
#  This file is part of the Waggle Platform.  Please see the file
#  LICENSE.waggle.txt for the legal details of the copyright and software
#  license.  For more details on the Waggle project, visit:
#           http://www.wa8.gl
# ANL:waggle-license
import argparse
import os
import time
import json
import numpy as np
import sys
import waggle.plugin
import multiprocessing
import cv2


config = {
    'source': 'bottom',
    'model': 'models/ssd_mobilenet_coco.pb',
    'model_desc': 'models/ssd_mobilenet_coco.pbtxt',
    'classes': 'models/ssd_mobilenet_coco.classes',
    'input_scale': 0.00784,
    'input_size': (300, 300),
    'input_mean_subtraction': (127.5, 127.5, 127.5),
    'input_channel_order': 'RGB',
    'detection_interval': 300,  # every 5 mins
    'sampling_interval': -1,  # None, by default
    'detection_confidence': 0.3,  # least detection confidence
}


def read_model_file(path, desc):
    model = read_model_file_using_ext(path, desc)
    # NOTE: Did not work in Waggle 2.9.0; needs investigation
    # Use OpenCL
    model.setPreferableBackend(cv2.dnn.DNN_BACKEND_DEFAULT)
    model.setPreferableTarget(cv2.dnn.DNN_TARGET_OPENCL)
    return model


def read_model_file_using_ext(path, desc):
    _, ext = os.path.splitext(path)
    if 'pb' in ext:
        return cv2.dnn.readNetFromTensorflow(path, desc)
    if 'caffemodel' in ext:
        return cv2.dnn.readNetFromCaffe(path, desc)
    raise ValueError(f'Model extension {ext} not recognized.')


def read_classes_file(path):
    classes = {}

    with open(path, 'r') as file:
        for line in file:
            sp = line.strip().split(' ')
            classes[int(sp[0])] = sp[1]

    return classes


def detect_objects(img_blob, cvNet, classes, confidence=0.3, img_rows=1, img_cols=1):
    cvNet.setInput(img_blob)
    cvOut = cvNet.forward()

    output = {}
    for detection in cvOut[0, 0, :, :]:
        score = float(detection[2])
        if score > confidence:
            class_index = int(detection[1])
            class_name = classes[class_index]
            if class_name not in output:
                output[class_name] = {}

            detection_index = len(output[class_name].keys())
            left = int(detection[3] * img_cols)
            top = int(detection[4] * img_rows)
            right = int(detection[5] * img_cols)
            bottom = int(detection[6] * img_rows)

            output[class_name][detection_index] = (
                left, top, right, bottom
            )
    return output


def get_class_count(detected_objects, name):
    return len(detected_objects.get(name, {}))


def open_video_capture(input):
    capture = cv2.VideoCapture(input)

    if not capture.isOpened():
        raise RuntimeError(f'could not open input {input}')

    return capture


def time_now():
    return time.monotonic()


def time_since(t):
    return time.monotonic() - t


def worker_main(args, heartbeat):
    print(f'opening input {args.input}', flush=True)
    capture = open_video_capture(args.input)

    # bind read_image function to capture
    def read_image():
        while True:
            _, img = capture.read()
            if img is not None:
                return img
            time.sleep(0.1)

    print(f'loading model and model config', flush=True)
    cvNet = read_model_file(config['model'], config['model_desc'])
    classes = read_classes_file(config['classes'])
    confidence = float(config.get('detection_confidence', 0.3))
    swapRB = 'RGB' in config['input_channel_order'].upper()

    if args.debug is not True:
        plugin = waggle.plugin.Plugin()

    last_publish_time = time_now()

    while True:
        heartbeat.put(1)

        print('reading image...', flush=True)
        img = read_image()
        print('read image', flush=True)

        img_blob = cv2.dnn.blobFromImage(
            img,
            config['input_scale'],
            config['input_size'],
            config['input_mean_subtraction'],
            swapRB=swapRB,
            crop=False
        )

        detected_objects = detect_objects(
            img_blob,
            cvNet,
            classes,
            confidence=confidence,
            img_rows=img.shape[0],
            img_cols=img.shape[1]
        )

        count_car = get_class_count(detected_objects, 'car')
        count_person = get_class_count(detected_objects, 'person')

        print(f'cars={count_car} pedestrians={count_person}', flush=True)

        if args.debug is not True and time_since(last_publish_time) > 30:
            last_publish_time = time_now()
            print('publishing this sample', flush=True)

            plugin.add_measurement({
                'id': 0x3001,
                'sub_id': 1,
                'value': count_car,
            })

            plugin.add_measurement({
                'id': 0x3001,
                'sub_id': 2,
                'value': count_person,
            })

            plugin.publish_measurements()


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--input', default='http://cam_bottom_live:8090/live')
    parser.add_argument('--debug', action='store_true')
    args = parser.parse_args()

    heartbeat = multiprocessing.Queue()
    worker = multiprocessing.Process(
        target=worker_main, args=(args, heartbeat))

    # TODO I couldn't figure out how to get a frame from cv2.VideoCapture without blocking
    # forever when as error occurs. I've organized the code so the video capture happens
    # in a worker process and is shared over a queue. This allows us to build in a timeout
    # to recover from a locked up camera.
    try:
        worker.start()
        while True:
            heartbeat.get(timeout=30)  # throws an exception on timeout
    except Exception:
        pass

    # if we reach this point, the worker process has stopped
    worker.terminate()
    raise RuntimeError('worker is no longer responding')


if __name__ == '__main__':
    main()
